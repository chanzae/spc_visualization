{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01cf3782",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1389d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait,Select\n",
    "from selenium.webdriver.support import expected_conditions as EC  #selenium에서 사용할 모듈 import\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import  urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2dd8e4",
   "metadata": {},
   "source": [
    "# Paris baguette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetURL(url):\n",
    "    driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\")  #selenium 사용에 필요한 chromedriver.exe 파일 경로 지정\n",
    "    driver.get(url) \n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def PageParser(driver):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    return soup\n",
    "\n",
    "def CountingDropDown(driver, option_num):\n",
    "    soup = PageParser(driver)\n",
    "    SelectArea = soup.find_all('div', class_ = \"selectric-hide-select\")\n",
    "    AreaList = SelectArea[option_num].select('option')\n",
    "    AreaCnt = len(AreaList)\n",
    "    \n",
    "    return AreaList, AreaCnt\n",
    "\n",
    "def SendDown(driver):\n",
    "    swapToActive = driver.switch_to.active_element\n",
    "    swapToActive.send_keys(Keys.DOWN)\n",
    "    swapToActive.send_keys(Keys.ENTER)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "def SelectSearchMode(driver):\n",
    "    search = driver.find_element_by_xpath('//*[@id=\"main\"]/div[1]/div[1]/div[1]/ul/li[2]/a')\n",
    "    search.click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89499a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "StoreDict= {'region':[], 'brand' : [], 'branch' :[], 'addr' :[]}\n",
    "url = 'https://www.paris.co.kr/store/'\n",
    "\n",
    "driver = GetURL(url)\n",
    "\n",
    "SelectSearchMode(driver)\n",
    "\n",
    "Area1List, CntDD1 = CountingDropDown(driver,0)\n",
    "\n",
    "for i in tqdm(range(CntDD1 - 1), desc = '지역별 정보 수집중.... '):\n",
    "    try:\n",
    "        #Area1 선택\n",
    "        WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"#main > div.store-map.show-timetable > div.store-control > div.store-control-header > div > form > div.location > div.selector.area1 > div\"))).click()\n",
    "        SendDown(driver)\n",
    "        \n",
    "        driver.switch_to.active_element\n",
    "\n",
    "        soup2 = PageParser(driver)\n",
    "        StoreArea = soup2.find(\"div\", class_ = \"store-list\")\n",
    "        StoreBranchs = StoreArea.find_all('span', class_ = 'label')\n",
    "        StoreAddrs = StoreArea.find_all('p', class_ = 'store-addr')\n",
    "\n",
    "        for br, addr in zip(StoreBranchs, StoreAddrs):\n",
    "            StoreDict['region'].append(Area1List[i+1].text)\n",
    "            StoreDict['brand'].append('파리바게뜨')\n",
    "            StoreDict['branch'].append(br.text)\n",
    "            StoreDict['addr'].append(addr.text)\n",
    "\n",
    "        time.sleep(5)\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error : Area1 {Area1List[i+1].text}\")\n",
    "        continue\n",
    "        \n",
    "driver.quit()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70d0d8",
   "metadata": {},
   "source": [
    "# Dunkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_city(cityvalue):\n",
    "    city = Select(driver.find_element_by_xpath('//*[@id=\"nform\"]/fieldset/p[1]/span[1]/select'))\n",
    "    city.select_by_index(str(cityvalue))\n",
    "    \n",
    "def click_gugun(gugunvalue):\n",
    "    gugun =Select(driver.find_element_by_xpath('//*[@id=\"nform\"]/fieldset/p[1]/span[2]/select'))\n",
    "    gugun.select_by_index(str(gugunvalue))\n",
    "\n",
    "def click_btn():\n",
    "    btn = driver.find_element_by_xpath('//*[@id=\"nform\"]/fieldset/div[2]/button')\n",
    "    btn.click()\n",
    "    \n",
    "def find_tag(tag,class_):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    lst = soup.find(tag, class_= class_)\n",
    "    \n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc196ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dunkindonuts.co.kr/store/map.php'\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\")  #selenium 사용에 필요한 chromedriver.exe 파일 경로 지정\n",
    "driver.get(url) \n",
    "\n",
    "time.sleep(3) #화면 표시 기다리기\n",
    "\n",
    "city_num = 17\n",
    "gugun_num = 40\n",
    "tmp_name = []\n",
    "tmp_addr = []\n",
    "\n",
    "for i in tqdm(range(1,city_num+1)):\n",
    "    click_city(i)\n",
    "    time.sleep(3)\n",
    "\n",
    "    for k in range(1,gugun_num+1):\n",
    "        try:\n",
    "            click_gugun(k)\n",
    "            click_btn()\n",
    "            \n",
    "            time.sleep(5)\n",
    "        \n",
    "            lst = find_tag('div','list')\n",
    "            names = lst.find_all('h3',class_=\"name\")\n",
    "            addrs = lst.find_all('span')\n",
    "\n",
    "            for name,addr in zip(names,addrs[::2]):\n",
    "                try:\n",
    "                    re_name = re.sub('[\\n\\t]+','',name.text)\n",
    "                    re_name = re.sub('^\\d+','',re_name)\n",
    "                    tmp_name.append(re_name)\n",
    "                    tmp_addr.append(addr.text)\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e061998",
   "metadata": {},
   "source": [
    "# Baskin robbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.baskinrobbins.co.kr/store/map.php'\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\")  #selenium 사용에 필요한 chromedriver.exe 파일 경로 지정\n",
    "driver.get(url) \n",
    "\n",
    "time.sleep(3) #화면 표시 기다리기\n",
    "\n",
    "city_num = 17\n",
    "gugun_num = 40\n",
    "tmp_name = []\n",
    "tmp_addr = []\n",
    "\n",
    "for c_num in tqdm(range(1,city_num+1)):\n",
    "    click_city(c_num)\n",
    "    time.sleep(3)\n",
    "\n",
    "    for g_num in range(1,gugun_num+1):\n",
    "        try:\n",
    "            click_gugun(g_num)\n",
    "            click_btn()\n",
    "            \n",
    "            time.sleep(5)\n",
    "            \n",
    "            lst = find_tag('div','list')\n",
    "            names = lst.find_all('h3',class_=\"name\")\n",
    "            addrs = lst.find_all(\"address\",class_=\"address\")\n",
    "\n",
    "            for name,addr in zip(names,addrs):\n",
    "                try:\n",
    "                    re_name = re.sub('[\\n\\t]+','',name.text)\n",
    "                    re_name = re.sub('^\\d+','',re_name)+'점'\n",
    "                    tmp_name.append(re_name)\n",
    "                    tmp_addr.append(re.sub('주소|[\\n\\t]+','',addr.text))\n",
    "                except:\n",
    "                    tmp_name.append(f'{c_num},{g_num}')\n",
    "                    tmp_addr.append(f'{c_num},{g_num}')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dc64f",
   "metadata": {},
   "source": [
    "# Naver maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67282f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_map_search(keyword, category):\n",
    "    map_addr = \"https://m.map.naver.com/search2/search.naver?query=\" + keyword\n",
    "\n",
    "    driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\")  #selenium 사용에 필요한 chromedriver.exe 파일 경로 지정\n",
    "    driver.get(map_addr) #네이버 모바일 지도 \n",
    "\n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "           EC.presence_of_element_located((By.CLASS_NAME, \"Nbox_text\"))\n",
    "        ) #입력창이 뜰 때까지 대기\n",
    "    finally:\n",
    "        pass\n",
    "\n",
    "    time.sleep(3) #화면 표시 기다리기\n",
    "\n",
    "    # 스크롤 끝까지 내리기\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:   # 0에서부터 영상 맨 마지막까지 긁음.\n",
    "\n",
    "        # 마우스 스크롤을 끝까지 내리겠음\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        time.sleep(3.0) \n",
    "\n",
    "        # 내린 스크롤까지의 높이를 구해서 변수에 넣음\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height: # 지금의 높이가 웹페이지의 끝이라면\n",
    "            break # 종료\n",
    "\n",
    "        last_page_height = new_page_height # 그렇지 않으면 계속 스크롤을 진행\n",
    "\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "    title = soup.find_all(\"div\", class_ = \"item_tit _title\")\n",
    "    address = soup.find_all(\"a\", class_ = \"item_address _btnAddress\")\n",
    "\n",
    "    temp_dict = {'brand': [], \n",
    "                 'name' : [], \n",
    "                 'branch': [], \n",
    "                 'addr' : []\n",
    "                }\n",
    "\n",
    "    for tit,addr in zip(title,address):\n",
    "        brand = keyword\n",
    "        name = tit.text.split(' ')[0]\n",
    "        branch = re.sub(category,'',tit.text[tit.text.find(' ')+1:])\n",
    "        tmpaddr = addr.text[re.search('\\s+', addr.text).end():]\n",
    "\n",
    "        temp_dict['brand'].append(brand)  #brand\n",
    "        temp_dict['name'].append(name)  #name\n",
    "        temp_dict['branch'].append(branch)  #branch\n",
    "        temp_dict['addr'].append(tmpaddr) #addr\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    print(\"Done\")\n",
    "    \n",
    "    return temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231df9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver_map_search(keyword, category)\n",
    "\n",
    "coffeeatworks = naver_map_search('커피앳웍스','카페')\n",
    "bizen = naver_map_search('빚은','떡,한과')\n",
    "shake = naver_map_search('쉐이크쉑','햄버거')\n",
    "jamba = naver_map_search('잠바주스','과일,주스전문점')\n",
    "linas = naver_map_search('리나스','샌드위치')\n",
    "piginthegarden = naver_map_search('피그인더가든','다이어트,샐러드')\n",
    "lagrillia = naver_map_search('피그인더가든','이탈리아음식')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cb86a",
   "metadata": {},
   "source": [
    "# 지방행정인허가데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964dd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Click_Xpath(xpath):\n",
    "    category = driver.find_element_by_xpath(xpath)\n",
    "    category.click()\n",
    "\n",
    "def search(keyword):\n",
    "    search_box = driver.find_element_by_class_name(\"input-keyword\")\n",
    "    search_box.send_keys(keyword)\n",
    "    search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "# 스크롤 내리기\n",
    "def ScrollDown():\n",
    "    # 스크롤 끝까지 내리기\n",
    "    last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "    while True:   # 0에서부터 영상 맨 마지막까지 긁음.\n",
    "\n",
    "        # 마우스 스크롤을 끝까지 내리겠음\n",
    "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "        time.sleep(3) \n",
    "\n",
    "        # 내린 스크롤까지의 높이를 구해서 변수에 넣음\n",
    "        new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "        if new_page_height == last_page_height: # 지금의 높이가 웹페이지의 끝이라면\n",
    "            break # 종료\n",
    "\n",
    "        last_page_height = new_page_height # 그렇지 않으면 계속 스크롤을 진행\n",
    "\n",
    "        \n",
    "# 페이지에서 info찾기\n",
    "def find_info():\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    names = soup.find_all('td',class_ = \"td-upso\")\n",
    "    addrs = soup.find_all('td',class_ = \"td-addr\")\n",
    "\n",
    "    tmp = {'name': [], 'addr' : []}\n",
    "    for name, addr in zip(names, addrs):\n",
    "        tmp['name'].append(name.text)\n",
    "        tmp['addr'].append(addr.text)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "# 페이지 검색 후 데이터 병합까지\n",
    "def page_search(data):\n",
    "    tmpData = data.copy()\n",
    "    \n",
    "    tmpInfo = find_info()\n",
    "    tmpData = pd.concat([tmpData, pd.DataFrame(tmpInfo)], axis = 0)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    return tmpData    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247c148",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.localdata.kr/data/dataView.do'\n",
    "data = pd.DataFrame({'name':[], 'addr': []})\n",
    "keyword = '베이커리팩토리'  # 베이커리 팩토리 \n",
    "\n",
    "###########################\n",
    "\n",
    "driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\")  #selenium 사용에 필요한 chromedriver.exe 파일 경로 지정\n",
    "driver.get(url) \n",
    "\n",
    "time.sleep(2) #화면 표시 기다리기\n",
    "\n",
    "# [식품] 선택\n",
    "Click_Xpath('//*[@id=\"categoryList\"]/ul/li[3]/div[1]')\n",
    "time.sleep(2)\n",
    "\n",
    "# [식품제조가공판매] 선택\n",
    "Click_Xpath('//*[@id=\"group\"]/div[2]/a')\n",
    "time.sleep(2)\n",
    "\n",
    "# [제과점영업] 선택\n",
    "Click_Xpath('//*[@id=\"opnLeftList\"]/li[16]/a/span')\n",
    "time.sleep(2)\n",
    "\n",
    "# 검색어 입력\n",
    "search(keyword)\n",
    "time.sleep(5)\n",
    "\n",
    "###########################\n",
    "\n",
    "ScrollDown()\n",
    "\n",
    "data = page_search(data)\n",
    "next_page = True\n",
    "\n",
    "try : \n",
    "    for num in tqdm(range(1,10), desc = 'first pages search...'):\n",
    "        Click_Xpath(f'//*[@id=\"navigator\"]/a[{num}]')\n",
    "        ScrollDown()\n",
    "\n",
    "        data = page_search(data)\n",
    "\n",
    "    Click_Xpath('//*[@id=\"navigator\"]/a[10]') # 다음 10페이지로 넘어가기\n",
    "    time.sleep(3)\n",
    "    \n",
    "except:\n",
    "    next_page = False\n",
    "\n",
    "\n",
    "if next_page == True:\n",
    "    cnt = 10\n",
    "    while True:\n",
    "        try:\n",
    "            ScrollDown()\n",
    "            data = page_search(data)\n",
    "\n",
    "            for num in tqdm(range(3,12), desc = f'{cnt} pages search...'):\n",
    "                Click_Xpath(f'//*[@id=\"navigator\"]/a[{num}]')\n",
    "                ScrollDown()\n",
    "\n",
    "                data = page_search(data)\n",
    "\n",
    "            Click_Xpath('//*[@id=\"navigator\"]/a[12]')# 다음 10페이지로 넘어가기\n",
    "            time.sleep(3)\n",
    "\n",
    "            cnt += 10\n",
    "\n",
    "        except:\n",
    "            break\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1de0b",
   "metadata": {},
   "source": [
    "# Pascucci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa62a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파스쿠찌 크롤링하는 코드\n",
    "page_num = 55\n",
    "temp = []\n",
    "\n",
    "for page in tqdm(range(1,page_num+1)):\n",
    "    list_url =\"https://www.caffe-pascucci.co.kr/store/storeList.asp?page=\" + str(page)\n",
    "     \n",
    "    driver = webdriver.Chrome(\"C:\\\\data\\\\chromedriver_win32\\\\chromedriver.exe\") # 크롬드라이버 불러옴\n",
    "    driver.implicitly_wait(5) # 10초 기다림\n",
    "    driver.get(list_url) # 위의 url을 가져옴\n",
    "    time.sleep(3)\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    name = soup.find_all(\"td\", class_ = \"storeName\")\n",
    "    address = soup.find_all(\"p\", class_ = \"addr\")\n",
    "    \n",
    "    for n,a in zip(name,address):\n",
    "        temp.append([n.string,a.string])\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6693605",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ac6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckDuplicate(dataframe):\n",
    "    checked_df = dataframe.copy()\n",
    "    checked_df['dup'] = checked_df.duplicated(keep=False)\n",
    "    \n",
    "    return checked_df[checked_df.dup == True]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
